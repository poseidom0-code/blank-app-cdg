#######################
# Import libraries
import streamlit as st
import pandas as pd
import altair as alt
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import (
    accuracy_score, confusion_matrix, classification_report,
    mean_squared_error, mean_absolute_error
)

#######################
# Page config
st.set_page_config(
    page_title="Titanic Dashboard",
    page_icon="ğŸš¢",
    layout="wide",
    initial_sidebar_state="expanded"
)
alt.themes.enable("default")

#######################
# Load data
df = pd.read_csv("titanic.csv")

#######################
# Sidebar
with st.sidebar:
    st.title("Titanic Survival Analysis Dashboard")
    st.header("ë°ì´í„° í•„í„°")

    pclass_filter = st.multiselect("Pclass ì„ íƒ", [1, 2, 3], default=[1, 2, 3])
    sex_filter = st.multiselect("ì„±ë³„ ì„ íƒ", ["male", "female"], default=["male", "female"])
    embarked_filter = st.multiselect("íƒ‘ìŠ¹ì§€ ì„ íƒ", ["C", "Q", "S"], default=["C", "Q", "S"])

    st.header("ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì˜µì…˜")
    missing_option = st.selectbox(
        "ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë°©ë²• ì„ íƒ",
        ["ì œê±°", "í‰ê·  ëŒ€ì²´", "ì¤‘ì•™ê°’ ëŒ€ì²´", "ìµœë¹ˆê°’ ëŒ€ì²´", "ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ"]
    )

    st.header("ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²• ì„ íƒ")
    ml_method = st.multiselect(
        "ì‚¬ìš©í•  ML ê¸°ë²•",
        ["ë¶„ë¥˜(Classification)", "íšŒê·€(Regression)", "êµ°ì§‘(Clustering)"]
    )

    run_analysis = st.button("ë¶„ì„ ì‹¤í–‰")

#######################
# Dashboard Layout
col = st.columns((1.5, 4.5, 2))

###############################################
# Column 1 : Summary
###############################################
with col[0]:
    st.subheader("ìš”ì•½ ì§€í‘œ")

    total_passengers = len(df)
    survived_rate = df["Survived"].mean() * 100
    avg_age = df["Age"].mean()
    avg_fare = df["Fare"].mean()

    st.metric("ì „ì²´ ìŠ¹ê° ìˆ˜", f"{total_passengers:,}")
    st.metric("ìƒì¡´ìœ¨", f"{survived_rate:.1f}%")
    st.metric("í‰ê·  ë‚˜ì´", f"{avg_age:.1f} ì„¸")
    st.metric("í‰ê·  ìš”ê¸ˆ (Fare)", f"{avg_fare:.2f}")

    st.markdown("---")

    st.subheader("ì„±ë³„ ìƒì¡´ìœ¨")
    sex_survival = df.groupby("Sex")["Survived"].mean() * 100
    st.write(pd.DataFrame({"ìƒì¡´ìœ¨(%)": sex_survival.round(1)}))

    st.markdown("---")

    st.subheader("Pclassë³„ ìƒì¡´ìœ¨")
    class_survival = df.groupby("Pclass")["Survived"].mean() * 100
    st.write(pd.DataFrame({"ìƒì¡´ìœ¨(%)": class_survival.round(1)}))

###############################################
# Column 2 : Visualization
###############################################
with col[1]:
    st.subheader("ì‹œê°í™” ë¶„ì„")

    st.markdown("### ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ")
    numeric_cols = ["Survived", "Age", "Fare", "SibSp", "Parch", "Pclass"]
    corr = df[numeric_cols].corr()

    fig, ax = plt.subplots(figsize=(6, 4))
    sns.heatmap(corr, annot=True, cmap="Blues", fmt=".2f", ax=ax)
    st.pyplot(fig)

    st.markdown("---")

    st.markdown("### ì—°ë ¹ ë¶„í¬ (Age Histogram)")
    fig2, ax2 = plt.subplots(figsize=(6, 4))
    sns.histplot(df["Age"], kde=True, bins=20, ax=ax2)
    st.pyplot(fig2)

    st.markdown("---")

    st.markdown("### Pclass Ã— Sex ìƒì¡´ìœ¨ íˆíŠ¸ë§µ")
    pivot_table = df.pivot_table(values="Survived", index="Pclass", columns="Sex", aggfunc="mean")

    fig3, ax3 = plt.subplots(figsize=(6, 4))
    sns.heatmap(pivot_table, annot=True, cmap="Greens", fmt=".2f")
    st.pyplot(fig3)

###############################################
# Column 3 : ML + Details
###############################################
with col[2]:
    st.subheader("ìƒì„¸ ë¶„ì„ ë° ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼")

    st.markdown("### ìƒì¡´/ë¹„ìƒì¡´ ê·¸ë£¹ í†µê³„")
    group_stats = df.groupby("Survived")[["Age", "Fare", "SibSp", "Parch"]].mean()
    group_stats = group_stats.rename(index={0: "ë¹„ìƒì¡´", 1: "ìƒì¡´"})
    st.dataframe(group_stats)
    st.markdown("---")

    st.subheader("### ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„ ê²°ê³¼")

    ############################
    # Classification
    ############################
    if "ë¶„ë¥˜(Classification)" in ml_method:
        st.markdown("#### ë¶„ë¥˜ ëª¨ë¸ (Logistic Regression)")

        X = df[["Pclass", "Age", "Fare", "SibSp", "Parch"]].copy()

        # ìˆ«ìí˜• ë³€í™˜
        X = X.apply(pd.to_numeric, errors="coerce")
        X = X.fillna(X.mean())

        y = df["Survived"]

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        model = LogisticRegression(max_iter=500)
        model.fit(X_train, y_train)
        preds = model.predict(X_test)

        st.write("Accuracy:", round(accuracy_score(y_test, preds), 3))
        st.write("Confusion Matrix:")
        st.write(confusion_matrix(y_test, preds))
        st.text(classification_report(y_test, preds))

        st.markdown("---")

    ############################
    # Regression
    ############################
    if "íšŒê·€(Regression)" in ml_method:
        st.markdown("#### íšŒê·€ ëª¨ë¸ (Fare ì˜ˆì¸¡)")

        reg_df = df[["Pclass", "Age", "SibSp", "Parch", "Fare"]].copy()
        reg_df = reg_df.apply(pd.to_numeric, errors="coerce").dropna()

        X = reg_df.drop("Fare", axis=1)
        y = reg_df["Fare"]

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        reg_model = LinearRegression()
        reg_model.fit(X_train, y_train)
        pred = reg_model.predict(X_test)

        rmse = mean_squared_error(y_test, pred, squared=False)
        mae = mean_absolute_error(y_test, pred)

        st.write("RMSE:", round(rmse, 3))
        st.write("MAE:", round(mae, 3))

        st.markdown("---")

    ############################
    # Clustering
    ############################
    if "êµ°ì§‘(Clustering)" in ml_method:
        st.markdown("#### êµ°ì§‘ ëª¨ë¸ (K-Means)")

        cluster_data = df[["Age", "Fare", "Pclass", "SibSp", "Parch"]].copy()
        cluster_data = cluster_data.apply(pd.to_numeric, errors="coerce").dropna()

        scaler = StandardScaler()
        scaled = scaler.fit_transform(cluster_data)

        pca = PCA(n_components=2)
        pca_data = pca.fit_transform(scaled)

        kmeans = KMeans(n_clusters=3, random_state=42)
        labels = kmeans.fit_predict(pca_data)

        fig, ax = plt.subplots(figsize=(5, 4))
        ax.scatter(pca_data[:, 0], pca_data[:, 1], c=labels)
        ax.set_xlabel("PCA 1")
        ax.set_ylabel("PCA 2")
        st.pyplot(fig)

        cluster_summary = pd.DataFrame({
            "í´ëŸ¬ìŠ¤í„°": labels,
            "Age": cluster_data["Age"].values,
            "Fare": cluster_data["Fare"].values
        }).groupby("í´ëŸ¬ìŠ¤í„°").mean()

        st.dataframe(cluster_summary)
